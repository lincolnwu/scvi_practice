{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61985781-f6a8-4857-b7c4-72aa27456cda",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import scvi\n",
    "import scanpy as sc\n",
    "\n",
    "sc.set_figure_params(figsize=(4, 4))\n",
    "\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eac067c-8b76-4252-b003-ad123951ec4d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scanpy==1.9.1 anndata==0.8.0 umap==0.5.3 numpy==1.23.4 scipy==1.9.3 pandas==1.5.1 scikit-learn==1.1.3 statsmodels==0.13.5 python-igraph==0.10.2 pynndescent==0.5.8\n"
     ]
    }
   ],
   "source": [
    "sc.settings.verbosity = 3             # verbosity: errors (0), warnings (1), info (2), hints (3)\n",
    "sc.logging.print_header()\n",
    "sc.settings.set_figure_params(dpi=80, facecolor='white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d153c46-3e5c-43b7-a835-846720d7ba51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import gene matrix, protein matrix, and list of genes for ensembl translation\n",
    "import anndata as ad\n",
    "gene_matrix_df = pd.read_csv(\"https://www.dropbox.com/s/910hhahxsbd9ofs/gene_matrix_all_new.csv?dl=1\", header=0, sep=\",\")\n",
    "# print(gene_matrix_df)\n",
    "\n",
    "protein_df = pd.read_csv(\"https://www.dropbox.com/s/xzobh2p13cqt4y5/protein_expr_all.csv?dl=1\", header=0, sep=\",\")\n",
    "# print(protein_df)\n",
    "\n",
    "genes_list_df = pd.read_csv(\"https://www.dropbox.com/s/11dmp8ki6tui2zu/genes.tsv?dl=1\", header=None, sep=\"\\t\")\n",
    "# print(genes_list_df)\n",
    "\n",
    "# Change first column of protein matrix to not be the index\n",
    "protein_df.reset_index(inplace=True)\n",
    "# print(protein_df.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e397b3e0-bc0b-48c5-8497-9e91b011b17c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index  m1_AAACCTGAGAGCAATT.1  m1_AAACCTGCAAGCTGTT.1  \\\n",
      "0      B220                   1072                    627   \n",
      "1     CD106                     10                      2   \n",
      "2     CD11b                     12                      5   \n",
      "3     CD11c                      5                      4   \n",
      "4   CD16.32                    118                     55   \n",
      "5     CD169                      6                      0   \n",
      "6      CD19                     59                     44   \n",
      "7   CD21.35                    163                     60   \n",
      "8      CD27                      4                      1   \n",
      "9       CD3                      4                      0   \n",
      "10     CD31                     46                     26   \n",
      "11     CD35                     43                     22   \n",
      "12      CD4                     13                      4   \n",
      "13     CD44                     34                     29   \n",
      "14     CD45                    719                    342   \n",
      "15      CD5                     16                      1   \n",
      "16     CD71                     34                     18   \n",
      "17    CD79b                    136                    140   \n",
      "18     CD8a                      4                      0   \n",
      "19     CD90                    121                     45   \n",
      "20    ERTR7                      9                      9   \n",
      "21    F4.80                     17                      5   \n",
      "22      IgD                    662                    718   \n",
      "23      IgM                     19                     13   \n",
      "24     Ly6C                     31                     13   \n",
      "25     Ly6G                      6                      5   \n",
      "26    MHCII                   2068                    309   \n",
      "27    NKp46                      2                      0   \n",
      "28      TCR                     16                      2   \n",
      "29   Ter119                      9                      7   \n",
      "\n",
      "    m1_AAACCTGCAGGATCGA.1  m1_AAACCTGCATCCAACA.1  m1_AAACCTGTCAGTCCCT.1  \\\n",
      "0                    3633                     17                   1770   \n",
      "1                       7                      5                      8   \n",
      "2                      18                      7                     10   \n",
      "3                       3                      0                      1   \n",
      "4                     444                     20                    211   \n",
      "5                       3                      1                      3   \n",
      "6                     161                      0                     73   \n",
      "7                     402                      8                    422   \n",
      "8                       3                      0                      2   \n",
      "9                       3                      8                      4   \n",
      "10                    174                     28                     89   \n",
      "11                    125                     12                    143   \n",
      "12                     24                    269                     17   \n",
      "13                    149                     97                     89   \n",
      "14                   2431                    386                   1139   \n",
      "15                     15                    108                     19   \n",
      "16                     81                      4                     42   \n",
      "17                    491                      1                    423   \n",
      "18                      8                      2                      1   \n",
      "19                    130                    983                     71   \n",
      "20                     24                      0                     10   \n",
      "21                     18                      8                     15   \n",
      "22                   2591                      6                   1497   \n",
      "23                     53                      7                    104   \n",
      "24                     38                     14                     22   \n",
      "25                     53                      2                     12   \n",
      "26                   7447                     42                   2153   \n",
      "27                      0                      0                      1   \n",
      "28                     11                     59                      7   \n",
      "29                     27                      6                      9   \n",
      "\n",
      "    m1_AAACCTGTCGTCCGTT.1  m1_AAACCTGTCTGTCTCG.1  m1_AAACGGGAGGCTAGAC.1  \\\n",
      "0                     595                    833                   1153   \n",
      "1                       7                      6                      5   \n",
      "2                      24                      1                      5   \n",
      "3                       3                      0                      2   \n",
      "4                      66                     78                    188   \n",
      "5                       2                      2                      1   \n",
      "6                      26                     27                     67   \n",
      "7                     148                    131                    199   \n",
      "8                       0                      2                      1   \n",
      "9                       2                      1                      1   \n",
      "10                     33                     46                     56   \n",
      "11                     49                     74                     45   \n",
      "12                      9                      1                      7   \n",
      "13                     16                     23                     48   \n",
      "14                    361                    483                    737   \n",
      "15                      2                      8                      2   \n",
      "16                     23                     26                     18   \n",
      "17                    133                     72                    257   \n",
      "18                      3                      3                      0   \n",
      "19                     38                     47                     42   \n",
      "20                      2                      7                     10   \n",
      "21                      7                     10                      9   \n",
      "22                    656                    537                   1421   \n",
      "23                     33                      8                     22   \n",
      "24                     15                     16                      9   \n",
      "25                      6                      5                      2   \n",
      "26                   1369                   2268                   1894   \n",
      "27                      0                      1                      4   \n",
      "28                      2                      1                      2   \n",
      "29                     10                     11                      9   \n",
      "\n",
      "    m1_AAACGGGCAATGAAAC.1  ...  m2_TTTGTCAAGAAGATTC.1  m2_TTTGTCAAGAGTTGGC.1  \\\n",
      "0                     542  ...                     20                     94   \n",
      "1                       4  ...                     16                      5   \n",
      "2                       3  ...                    664                      6   \n",
      "3                       2  ...                     16                      5   \n",
      "4                      55  ...                    125                     57   \n",
      "5                       0  ...                      4                      1   \n",
      "6                      22  ...                      5                     39   \n",
      "7                      78  ...                     18                    117   \n",
      "8                       2  ...                      7                      1   \n",
      "9                       1  ...                      7                      2   \n",
      "10                     29  ...                      9                     36   \n",
      "11                     25  ...                     30                     31   \n",
      "12                      5  ...                      6                      3   \n",
      "13                     26  ...                    360                    508   \n",
      "14                    353  ...                    406                    429   \n",
      "15                      3  ...                      8                     62   \n",
      "16                     15  ...                     27                     26   \n",
      "17                     69  ...                      9                     38   \n",
      "18                      0  ...                      2                      2   \n",
      "19                     44  ...                    426                     93   \n",
      "20                      4  ...                      0                      0   \n",
      "21                     12  ...                     83                      9   \n",
      "22                    699  ...                     13                     28   \n",
      "23                     25  ...                     12                     26   \n",
      "24                     11  ...                     69                      8   \n",
      "25                      8  ...                     14                      5   \n",
      "26                    934  ...                    359                   3420   \n",
      "27                      0  ...                      6                      0   \n",
      "28                      5  ...                      7                      4   \n",
      "29                      5  ...                      5                      5   \n",
      "\n",
      "    m2_TTTGTCACAGCCTATA.1  m2_TTTGTCACAGGAATGC.1  m2_TTTGTCACAGTGACAG.1  \\\n",
      "0                      18                    617                    430   \n",
      "1                       4                     50                     15   \n",
      "2                     586                     17                     18   \n",
      "3                       3                      8                      2   \n",
      "4                     194                    246                     53   \n",
      "5                       6                      6                      0   \n",
      "6                       3                     44                     24   \n",
      "7                      17                    121                     63   \n",
      "8                       5                      9                      4   \n",
      "9                       4                      4                      0   \n",
      "10                     19                     31                     47   \n",
      "11                     19                    124                     11   \n",
      "12                      5                     11                      3   \n",
      "13                    360                     73                     63   \n",
      "14                    234                    404                    580   \n",
      "15                      6                     13                      6   \n",
      "16                     13                     81                     16   \n",
      "17                     11                    126                    121   \n",
      "18                      3                      4                      7   \n",
      "19                    325                    135                     61   \n",
      "20                      1                     11                      3   \n",
      "21                     84                     23                     17   \n",
      "22                     13                    557                    514   \n",
      "23                     16                     53                     21   \n",
      "24                   3534                     26                     14   \n",
      "25                      7                     29                      1   \n",
      "26                     29                    424                    669   \n",
      "27                      1                      0                      9   \n",
      "28                     10                     68                      2   \n",
      "29                     14                    388                      4   \n",
      "\n",
      "    m2_TTTGTCAGTTGGAGGT.1  m2_TTTGTCAGTTTGTTTC.1  m2_TTTGTCATCAACTCTT.1  \\\n",
      "0                     514                    718                   1305   \n",
      "1                       4                      5                      8   \n",
      "2                       6                      9                      2   \n",
      "3                       2                      7                      9   \n",
      "4                      73                     77                    151   \n",
      "5                       1                      1                      1   \n",
      "6                      39                     32                     70   \n",
      "7                     109                    134                    201   \n",
      "8                       4                      3                      1   \n",
      "9                       1                      1                      0   \n",
      "10                     18                     40                     53   \n",
      "11                     34                     74                     52   \n",
      "12                      9                      5                      1   \n",
      "13                      8                     28                     78   \n",
      "14                    324                    553                   1125   \n",
      "15                      2                      6                      3   \n",
      "16                     14                     19                     32   \n",
      "17                     63                    149                    267   \n",
      "18                      0                      4                      3   \n",
      "19                     29                     64                     48   \n",
      "20                      4                      5                     10   \n",
      "21                     11                     16                     10   \n",
      "22                    360                    330                   1121   \n",
      "23                     26                     27                     89   \n",
      "24                      4                      7                     13   \n",
      "25                     11                     13                      7   \n",
      "26                   1127                   1019                   1175   \n",
      "27                      0                      0                      0   \n",
      "28                      4                      1                      7   \n",
      "29                      6                     11                      4   \n",
      "\n",
      "    m2_TTTGTCATCACGACTA.1  m2_TTTGTCATCGTGGACC.1  \n",
      "0                     520                      6  \n",
      "1                       9                     26  \n",
      "2                       5                      4  \n",
      "3                       0                      1  \n",
      "4                      60                     23  \n",
      "5                       0                      0  \n",
      "6                      39                      0  \n",
      "7                      71                      7  \n",
      "8                       1                      8  \n",
      "9                       0                      8  \n",
      "10                     25                      5  \n",
      "11                     19                      6  \n",
      "12                      0                      2  \n",
      "13                     40                    233  \n",
      "14                    397                    570  \n",
      "15                      1                     48  \n",
      "16                     15                      3  \n",
      "17                    213                      4  \n",
      "18                      3                    152  \n",
      "19                     28                   1297  \n",
      "20                      6                      0  \n",
      "21                     19                      9  \n",
      "22                    704                     15  \n",
      "23                     24                      2  \n",
      "24                     11                    150  \n",
      "25                      5                      3  \n",
      "26                    700                     54  \n",
      "27                      0                      1  \n",
      "28                      6                     24  \n",
      "29                      9                      4  \n",
      "\n",
      "[30 rows x 7098 columns]\n"
     ]
    }
   ],
   "source": [
    "# Removing ADT_ prefix from proteins (colname function in R)\n",
    "import re\n",
    "def clean_adt(cite_protein_df):\n",
    "    cite_protein_df_copy = cite_protein_df.copy(deep=True)\n",
    "    cite_protein_df_copy.iloc[:,0] = cite_protein_df_copy.iloc[:,0].apply(lambda x: re.sub(\"ADT_\", \"\", x))\n",
    "    return cite_protein_df_copy\n",
    "\n",
    "# test = clean_adt(protein_df)\n",
    "# print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f72d1b19-0ec2-4fb0-8183-06211be7fb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ensembl names to gene names\n",
    "def convert_ensembl(gene_matrix_df, genes_list_df):\n",
    "    # Copy of gene matrix\n",
    "    gene_matrix_df_copy = gene_matrix_df.copy(deep=True)\n",
    "    \n",
    "    # Transpose\n",
    "    gene_matrix_df_copy_transposed = gene_matrix_df_copy.T\n",
    "    \n",
    "    # Create dictionary from gene list for translating ensembl names\n",
    "    genes_list_dict = dict(zip(genes_list_df[0], genes_list_df[1]))\n",
    "    \n",
    "    # Return a new matrix\n",
    "    translated_matrix = gene_matrix_df_copy_transposed.rename(columns = lambda x: genes_list_dict.get(x))\n",
    "    return translated_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a73e576-ebd1-46f2-9adc-41191c19d741",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Mrpl15  Lypla1  Tcea1  Atp6v1h  Rb1cc1  4732440D04Rik  \\\n",
      "m1_AAACCTGAGAGCAATT.1       0       0      0        0       0              0   \n",
      "m1_AAACCTGCAAGCTGTT.1       0       0      0        0       0              0   \n",
      "m1_AAACCTGCAGGATCGA.1       0       0      0        1       1              1   \n",
      "m1_AAACCTGCATCCAACA.1       0       0      0        0       0              0   \n",
      "m1_AAACCTGTCAGTCCCT.1       1       0      1        0       0              0   \n",
      "...                       ...     ...    ...      ...     ...            ...   \n",
      "m2_TTTGTCAGTTGGAGGT.1       1       0      0        0       0              0   \n",
      "m2_TTTGTCAGTTTGTTTC.1       0       0      1        1       0              0   \n",
      "m2_TTTGTCATCAACTCTT.1       0       0      1        0       1              0   \n",
      "m2_TTTGTCATCACGACTA.1       0       0      0        0       0              0   \n",
      "m2_TTTGTCATCGTGGACC.1       1       1      1        1       0              0   \n",
      "\n",
      "                       Pcmtd1  Gm26901  Rrs1  Vcpip1  ...  AC133103.1  \\\n",
      "m1_AAACCTGAGAGCAATT.1       0        0     0       1  ...           0   \n",
      "m1_AAACCTGCAAGCTGTT.1       0        0     0       0  ...           0   \n",
      "m1_AAACCTGCAGGATCGA.1       0        0     0       0  ...           0   \n",
      "m1_AAACCTGCATCCAACA.1       0        0     0       0  ...           0   \n",
      "m1_AAACCTGTCAGTCCCT.1       0        0     0       0  ...           1   \n",
      "...                       ...      ...   ...     ...  ...         ...   \n",
      "m2_TTTGTCAGTTGGAGGT.1       0        0     0       0  ...           0   \n",
      "m2_TTTGTCAGTTTGTTTC.1       1        0     0       0  ...           0   \n",
      "m2_TTTGTCATCAACTCTT.1       0        0     0       1  ...           0   \n",
      "m2_TTTGTCATCACGACTA.1       0        0     0       0  ...           0   \n",
      "m2_TTTGTCATCGTGGACC.1       0        0     0       0  ...           0   \n",
      "\n",
      "                       AC132444.1  Csprs  AC125149.3  AC125149.2  AC168977.2  \\\n",
      "m1_AAACCTGAGAGCAATT.1           0      0           0           0           0   \n",
      "m1_AAACCTGCAAGCTGTT.1           0      0           0           0           0   \n",
      "m1_AAACCTGCAGGATCGA.1           0      1           0           0           0   \n",
      "m1_AAACCTGCATCCAACA.1           0      0           0           0           0   \n",
      "m1_AAACCTGTCAGTCCCT.1           0      0           0           0           0   \n",
      "...                           ...    ...         ...         ...         ...   \n",
      "m2_TTTGTCAGTTGGAGGT.1           0      0           0           0           0   \n",
      "m2_TTTGTCAGTTTGTTTC.1           0      2           0           0           0   \n",
      "m2_TTTGTCATCAACTCTT.1           0      0           0           0           0   \n",
      "m2_TTTGTCATCACGACTA.1           0      0           0           0           0   \n",
      "m2_TTTGTCATCGTGGACC.1           0      1           0           0           0   \n",
      "\n",
      "                       AC168977.1  PISD  DHRSX  CAAA01147332.1  \n",
      "m1_AAACCTGAGAGCAATT.1           0     0      0               0  \n",
      "m1_AAACCTGCAAGCTGTT.1           0     0      0               0  \n",
      "m1_AAACCTGCAGGATCGA.1           0     0      0               0  \n",
      "m1_AAACCTGCATCCAACA.1           0     0      0               0  \n",
      "m1_AAACCTGTCAGTCCCT.1           0     0      0               0  \n",
      "...                           ...   ...    ...             ...  \n",
      "m2_TTTGTCAGTTGGAGGT.1           0     0      0               0  \n",
      "m2_TTTGTCAGTTTGTTTC.1           0     0      0               0  \n",
      "m2_TTTGTCATCAACTCTT.1           0     0      0               0  \n",
      "m2_TTTGTCATCACGACTA.1           0     0      0               0  \n",
      "m2_TTTGTCATCGTGGACC.1           0     0      0               0  \n",
      "\n",
      "[7097 rows x 11713 columns]\n"
     ]
    }
   ],
   "source": [
    "# Translate ensembl names\n",
    "converted_matrix = convert_ensembl(gene_matrix_df, genes_list_df)\n",
    "print(converted_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1fd8183-183f-4e3f-93a8-f81e1a185199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m1_AAACCTGAGAGCAATT.1    2457\n",
      "m1_AAACCTGCAAGCTGTT.1    1497\n",
      "m1_AAACCTGCAGGATCGA.1    8026\n",
      "m1_AAACCTGCATCCAACA.1    1332\n",
      "m1_AAACCTGTCAGTCCCT.1    3883\n",
      "                         ... \n",
      "m2_TTTGTCAGTTGGAGGT.1    1580\n",
      "m2_TTTGTCAGTTTGTTTC.1    2908\n",
      "m2_TTTGTCATCAACTCTT.1    3701\n",
      "m2_TTTGTCATCACGACTA.1    1320\n",
      "m2_TTTGTCATCGTGGACC.1    3656\n",
      "Length: 7097, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Find number of genes per sample \n",
    "num_genes = converted_matrix.sum(axis = 1)\n",
    "print(num_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64f8731b-e24d-4d08-aaa7-1db5a5699632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       percent mito\n",
      "m1_AAACCTGAGAGCAATT.1             0\n",
      "m1_AAACCTGCAAGCTGTT.1             0\n",
      "m1_AAACCTGCAGGATCGA.1             0\n",
      "m1_AAACCTGCATCCAACA.1             0\n",
      "m1_AAACCTGTCAGTCCCT.1             0\n",
      "...                             ...\n",
      "m2_TTTGTCAGTTGGAGGT.1             0\n",
      "m2_TTTGTCAGTTTGTTTC.1             0\n",
      "m2_TTTGTCATCAACTCTT.1             0\n",
      "m2_TTTGTCATCACGACTA.1             0\n",
      "m2_TTTGTCATCGTGGACC.1             0\n",
      "\n",
      "[7097 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "percent_mito = pd.DataFrame(converted_matrix.iloc[:,0])\n",
    "percent_mito.rename(columns={ percent_mito.columns[0]: \"percent mito\" }, inplace=True)\n",
    "percent_mito['percent mito'] = 0\n",
    "print(percent_mito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1700f66b-ef88-4d25-a2ee-52d7e147f484",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 7097 × 11713\n",
      "    obsm: 'gene_expression'\n",
      "AnnData object with n_obs × n_vars = 7097 × 11713\n",
      "    obs: 'n_genes', 'percent_mito'\n",
      "    obsm: 'gene_expression'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/anndata/_core/anndata.py:1830: UserWarning: Variable names are not unique. To make them unique, call `.var_names_make_unique`.\n",
      "  utils.warn_names_duplicates(\"var\")\n"
     ]
    }
   ],
   "source": [
    "# Create anndata object\n",
    "\n",
    "\n",
    "# Set observations x variables data matrix (the dimensions)\n",
    "adata = ad.AnnData(converted_matrix, dtype=\"int64\")\n",
    "# print(adata)\n",
    "\n",
    "# Add gene matrix to obsm (observation/variable level matrices) used for umap embedding\n",
    "adata.obsm[\"gene_expression\"] = converted_matrix\n",
    "# print(adata)\n",
    "\n",
    "# Add n_genes to obs\n",
    "adata.obs[\"n_genes\"] = num_genes\n",
    "\n",
    "# Add percent mito to obs\n",
    "adata.obs[\"percent_mito\"] = percent_mito\n",
    "\n",
    "# print(adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df517bfd-2171-4505-aaa1-13bbcf2339c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing counts per cell\n",
      "    finished (0:00:00)\n",
      "AnnData object with n_obs × n_vars = 7097 × 11713\n",
      "    obs: 'n_genes', 'percent_mito'\n",
      "    uns: 'log1p'\n",
      "    obsm: 'gene_expression'\n",
      "    layers: 'counts'\n"
     ]
    }
   ],
   "source": [
    "# Continue building adata\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "\n",
    "# Normalize data\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "print(adata)\n",
    "adata.raw = adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "440f1d87-65a4-44b7-a531-ab55bb96d883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you pass `n_top_genes`, all cutoffs are ignored.\n",
      "extracting highly variable genes\n",
      "--> added\n",
      "    'highly_variable', boolean vector (adata.var)\n",
      "    'highly_variable_rank', float vector (adata.var)\n",
      "    'means', float vector (adata.var)\n",
      "    'variances', float vector (adata.var)\n",
      "    'variances_norm', float vector (adata.var)\n"
     ]
    }
   ],
   "source": [
    "# Feature selection\n",
    "sc.pp.highly_variable_genes(\n",
    "    adata, \n",
    "    n_top_genes=4000, \n",
    "    flavor=\"seurat_v3\",\n",
    "    batch_key=None, \n",
    "    subset=True,\n",
    "    layer=\"counts\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9c0d7d04-1beb-4832-a71a-91649cee5861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m Using column names from columns of adata.obsm\u001b[1m[\u001b[0m\u001b[32m'gene_expression'\u001b[0m\u001b[1m]\u001b[0m                                          \n"
     ]
    }
   ],
   "source": [
    "scvi.model.TOTALVI.setup_anndata(\n",
    "    adata, \n",
    "    protein_expression_obsm_key=\"gene_expression\",\n",
    "    layer=\"counts\", \n",
    "    batch_key=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "34247240-91e4-4f68-8184-21e725ca768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mINFO    \u001b[0m Computing empirical prior initialization for protein background.                                          \n"
     ]
    }
   ],
   "source": [
    "# Prepare and run model\n",
    "vae = scvi.model.TOTALVI(adata, latent_distribution=\"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "406e4e09-2358-41d3-8088-9e52220170f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Torchmetrics v0.9 introduced a new argument class property called `full_state_update` that has\n",
      "                not been set for this class (ElboMetric). The property determines if `update` by\n",
      "                default needs access to the full metric state. If this is not the case, significant speedups can be\n",
      "                achieved and we recommend setting this to `False`.\n",
      "                We provide an checking function\n",
      "                `from torchmetrics.utilities import check_forward_full_state_property`\n",
      "                that can be used to check if the `full_state_update=True` (old and potential slower behaviour,\n",
      "                default for now) or if `full_state_update=False` can be used safely.\n",
      "                \n",
      "  warnings.warn(*args, **kwargs)\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/400:  48%|█████████▋          | 193/400 [44:57<47:42, 13.83s/it, loss=5.52e+04, v_num=1]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected parameter scale (Tensor of shape (256, 11713)) of distribution Normal(loc: torch.Size([256, 11713]), scale: torch.Size([256, 11713])) to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\ntensor([[1.4013e-45, 2.8026e-45, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [2.6048e-22, 9.6073e-22, 9.6889e-25,  ..., 3.9440e-25, 2.1736e-26,\n         1.3464e-25],\n        [4.8851e-21, 6.1333e-20, 6.3796e-23,  ..., 3.7853e-23, 2.4766e-24,\n         1.4997e-23],\n        ...,\n        [6.9813e-10, 3.0768e-07, 3.8446e-08,  ..., 3.6186e-07, 2.2164e-07,\n         3.9703e-07],\n        [5.9167e-34, 3.0431e-33, 4.7018e-38,  ..., 6.6850e-39, 1.8168e-41,\n         3.4595e-39],\n        [4.2039e-45, 1.8217e-44, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00]])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scvi/model/_totalvi.py:305\u001b[0m, in \u001b[0;36mTOTALVI.train\u001b[0;34m(self, max_epochs, lr, use_gpu, train_size, validation_size, batch_size, early_stopping, check_val_every_n_epoch, reduce_lr_on_plateau, n_steps_kl_warmup, n_epochs_kl_warmup, adversarial_classifier, plan_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m training_plan \u001b[38;5;241m=\u001b[39m AdversarialTrainingPlan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mplan_kwargs)\n\u001b[1;32m    295\u001b[0m runner \u001b[38;5;241m=\u001b[39m TrainRunner(\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    297\u001b[0m     training_plan\u001b[38;5;241m=\u001b[39mtraining_plan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    304\u001b[0m )\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrunner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scvi/train/_trainrunner.py:74\u001b[0m, in \u001b[0;36mTrainRunner.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_splitter, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_val\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_plan\u001b[38;5;241m.\u001b[39mn_obs_validation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_splitter\u001b[38;5;241m.\u001b[39mn_val\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_plan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_splitter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_history()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# data splitter only gets these attrs after fit\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scvi/train/_trainer.py:186\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], PyroTrainingPlan):\n\u001b[1;32m    181\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[1;32m    182\u001b[0m         action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    183\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    184\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`LightningModule.configure_optimizers` returned `None`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    185\u001b[0m     )\n\u001b[0;32m--> 186\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:740\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    735\u001b[0m     rank_zero_deprecation(\n\u001b[1;32m    736\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`trainer.fit(train_dataloader)` is deprecated in v1.4 and will be removed in v1.6.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    737\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Use `trainer.fit(train_dataloaders)` instead. HINT: added \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    738\u001b[0m     )\n\u001b[1;32m    739\u001b[0m     train_dataloaders \u001b[38;5;241m=\u001b[39m train_dataloader\n\u001b[0;32m--> 740\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:685\u001b[0m, in \u001b[0;36mTrainer._call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;124;03mError handling, intended to be used only for main trainer function entry points (fit, validate, test, predict)\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;124;03mas all errors should funnel through them\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;124;03m    **kwargs: keyword arguments to be passed to `trainer_fn`\u001b[39;00m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;66;03m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:777\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;66;03m# TODO: ckpt_path only in v1.7\u001b[39;00m\n\u001b[1;32m    776\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m ckpt_path \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint\n\u001b[0;32m--> 777\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1199\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheckpoint_connector\u001b[38;5;241m.\u001b[39mresume_end()\n\u001b[1;32m   1198\u001b[0m \u001b[38;5;66;03m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[39;00m\n\u001b[0;32m-> 1199\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;66;03m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[39;00m\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post_dispatch()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1279\u001b[0m, in \u001b[0;36mTrainer._dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_type_plugin\u001b[38;5;241m.\u001b[39mstart_predicting(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1279\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_type_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_training\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:202\u001b[0m, in \u001b[0;36mTrainingTypePlugin.start_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstart_training\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;66;03m# double dispatch to initiate the training loop\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_results \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1289\u001b[0m, in \u001b[0;36mTrainer.run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredicting:\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1319\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mtrainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   1318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1319\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:234\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m data_fetcher \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mget_profiled_dataloader(dataloader)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# the global step is manually decreased here due to backwards compatibility with existing loggers\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;66;03m# as they expect that the same step is used when logging epoch end metrics even when the batch loop has\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# finished. this means the attribute does not exactly track the number of optimizer steps applied.\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# TODO(@carmocca): deprecate and rename so users don't get confused\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/base.py:146\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:242\u001b[0m, in \u001b[0;36mTrainingEpochLoop.on_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_check_val:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mvalidating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# -----------------------------------------\u001b[39;00m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;66;03m# SAVE LOGGERS (ie: Tensorboard, etc...)\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# -----------------------------------------\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:337\u001b[0m, in \u001b[0;36mTrainingEpochLoop._run_validation\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_loop\u001b[38;5;241m.\u001b[39m_reload_evaluation_dataloaders()\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:110\u001b[0m, in \u001b[0;36mEvaluationLoop.advance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_fetcher \u001b[38;5;241m=\u001b[39m dataloader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mget_profiled_dataloader(\n\u001b[1;32m    106\u001b[0m     dataloader, dataloader_idx\u001b[38;5;241m=\u001b[39mdataloader_idx\n\u001b[1;32m    107\u001b[0m )\n\u001b[1;32m    108\u001b[0m dl_max_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_batches[dataloader_idx]\n\u001b[0;32m--> 110\u001b[0m dl_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl_max_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_dataloaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# store batch level output per dataloader\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs\u001b[38;5;241m.\u001b[39mappend(dl_outputs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/base.py:145\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 145\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:122\u001b[0m, in \u001b[0;36mEvaluationEpochLoop.advance\u001b[0;34m(self, data_fetcher, dataloader_idx, dl_max_batches, num_dataloaders)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# lightning module methods\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_step_and_end\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 122\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluation_step_end(output)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_progress\u001b[38;5;241m.\u001b[39mincrement_processed()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py:217\u001b[0m, in \u001b[0;36mEvaluationEpochLoop._evaluation_step\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_step\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 217\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/accelerators/accelerator.py:236\u001b[0m, in \u001b[0;36mAccelerator.validation_step\u001b[0;34m(self, step_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;124;03m\"\"\"The actual validation step.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[38;5;124;03mSee :meth:`~pytorch_lightning.core.lightning.LightningModule.validation_step` for more details\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mval_step_context():\n\u001b[0;32m--> 236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_type_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstep_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py:219\u001b[0m, in \u001b[0;36mTrainingTypePlugin.validation_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidation_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scvi/train/_trainingplans.py:282\u001b[0m, in \u001b[0;36mTrainingPlan.validation_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidation_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch, batch_idx):\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;66;03m# loss kwargs here contains `n_obs` equal to n_training_obs\u001b[39;00m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# so when relevant, the actual loss value is rescaled to number\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# of training examples\u001b[39;00m\n\u001b[0;32m--> 282\u001b[0m     _, _, scvi_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m, scvi_loss\u001b[38;5;241m.\u001b[39mloss, on_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_and_log_metrics(scvi_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melbo_val)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scvi/train/_trainingplans.py:187\u001b[0m, in \u001b[0;36mTrainingPlan.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;124;03m\"\"\"Passthrough to `model.forward()`.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scvi/module/base/_decorators.py:41\u001b[0m, in \u001b[0;36mauto_move_data.<locals>.auto_transfer_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m args \u001b[38;5;241m=\u001b[39m _move_data_to_device(args, device)\n\u001b[1;32m     40\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m _move_data_to_device(kwargs, device)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scvi/module/base/_base_module.py:152\u001b[0m, in \u001b[0;36mBaseModuleClass.forward\u001b[0;34m(self, tensors, get_inference_input_kwargs, get_generative_input_kwargs, inference_kwargs, generative_kwargs, loss_kwargs, compute_loss)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;129m@auto_move_data\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    129\u001b[0m     Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor, LossRecorder],\n\u001b[1;32m    130\u001b[0m ]:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Forward pass through the network.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m        another return value.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_generic_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43minference_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgenerative_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_inference_input_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mget_generative_input_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompute_loss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scvi/module/base/_base_module.py:495\u001b[0m, in \u001b[0;36m_generic_forward\u001b[0;34m(module, tensors, inference_kwargs, generative_kwargs, loss_kwargs, get_inference_input_kwargs, get_generative_input_kwargs, compute_loss)\u001b[0m\n\u001b[1;32m    491\u001b[0m inference_outputs \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39minference(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minference_inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minference_kwargs)\n\u001b[1;32m    492\u001b[0m generative_inputs \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_get_generative_input(\n\u001b[1;32m    493\u001b[0m     tensors, inference_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mget_generative_input_kwargs\n\u001b[1;32m    494\u001b[0m )\n\u001b[0;32m--> 495\u001b[0m generative_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerative\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerative_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerative_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute_loss:\n\u001b[1;32m    497\u001b[0m     losses \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39mloss(\n\u001b[1;32m    498\u001b[0m         tensors, inference_outputs, generative_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs\n\u001b[1;32m    499\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scvi/module/base/_decorators.py:41\u001b[0m, in \u001b[0;36mauto_move_data.<locals>.auto_transfer_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m args \u001b[38;5;241m=\u001b[39m _move_data_to_device(args, device)\n\u001b[1;32m     40\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m _move_data_to_device(kwargs, device)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scvi/module/_totalvae.py:393\u001b[0m, in \u001b[0;36mTOTALVAE.generative\u001b[0;34m(self, z, library_gene, batch_index, label, cont_covs, cat_covs, size_factor, transform_batch)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_size_factor_key:\n\u001b[1;32m    391\u001b[0m     size_factor \u001b[38;5;241m=\u001b[39m library_gene\n\u001b[0;32m--> 393\u001b[0m px_, py_, log_pro_back_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize_factor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcategorical_input\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgene_dispersion \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgene-label\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;66;03m# px_r gets transposed - last dimension is nb genes\u001b[39;00m\n\u001b[1;32m    399\u001b[0m     px_r \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mlinear(one_hot(label, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_labels), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpx_r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/scvi/nn/_base_components.py:873\u001b[0m, in \u001b[0;36mDecoderTOTALVI.forward\u001b[0;34m(self, z, library_gene, *cat_list)\u001b[0m\n\u001b[1;32m    869\u001b[0m py_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mback_alpha\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpy_back_mean_log_alpha(py_back_cat_z, \u001b[38;5;241m*\u001b[39mcat_list)\n\u001b[1;32m    870\u001b[0m py_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mback_beta\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpy_back_mean_log_beta(py_back_cat_z, \u001b[38;5;241m*\u001b[39mcat_list)\n\u001b[1;32m    872\u001b[0m )\n\u001b[0;32m--> 873\u001b[0m log_pro_back_mean \u001b[38;5;241m=\u001b[39m \u001b[43mNormal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpy_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mback_alpha\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpy_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mback_beta\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrsample()\n\u001b[1;32m    874\u001b[0m py_[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrate_back\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(log_pro_back_mean)\n\u001b[1;32m    876\u001b[0m py_fore \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpy_fore_decoder(z, \u001b[38;5;241m*\u001b[39mcat_list)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/distributions/normal.py:54\u001b[0m, in \u001b[0;36mNormal.__init__\u001b[0;34m(self, loc, scale, validate_args)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     batch_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloc\u001b[38;5;241m.\u001b[39msize()\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mNormal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatch_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/distributions/distribution.py:55\u001b[0m, in \u001b[0;36mDistribution.__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     53\u001b[0m         valid \u001b[38;5;241m=\u001b[39m constraint\u001b[38;5;241m.\u001b[39mcheck(value)\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m valid\u001b[38;5;241m.\u001b[39mall():\n\u001b[0;32m---> 55\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     56\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected parameter \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtuple\u001b[39m(value\u001b[38;5;241m.\u001b[39mshape)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     58\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof distribution \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     59\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto satisfy the constraint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(constraint)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     60\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut found invalid values:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     61\u001b[0m             )\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28msuper\u001b[39m(Distribution, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: Expected parameter scale (Tensor of shape (256, 11713)) of distribution Normal(loc: torch.Size([256, 11713]), scale: torch.Size([256, 11713])) to satisfy the constraint GreaterThan(lower_bound=0.0), but found invalid values:\ntensor([[1.4013e-45, 2.8026e-45, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00],\n        [2.6048e-22, 9.6073e-22, 9.6889e-25,  ..., 3.9440e-25, 2.1736e-26,\n         1.3464e-25],\n        [4.8851e-21, 6.1333e-20, 6.3796e-23,  ..., 3.7853e-23, 2.4766e-24,\n         1.4997e-23],\n        ...,\n        [6.9813e-10, 3.0768e-07, 3.8446e-08,  ..., 3.6186e-07, 2.2164e-07,\n         3.9703e-07],\n        [5.9167e-34, 3.0431e-33, 4.7018e-38,  ..., 6.6850e-39, 1.8168e-41,\n         3.4595e-39],\n        [4.2039e-45, 1.8217e-44, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n         0.0000e+00]])"
     ]
    }
   ],
   "source": [
    "vae.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
